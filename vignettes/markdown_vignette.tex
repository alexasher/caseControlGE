\documentclass[11pt,]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=0.75in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Semiparametric Analysis of Polygenic Gene-Environment Interactions in Case-Control Studies with caseControlGE},
            pdfauthor={Alex Asher},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{Semiparametric Analysis of Polygenic Gene-Environment Interactions in
Case-Control Studies with caseControlGE}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \author{Alex Asher}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{June, 2018}

% \usepackage{amsmath}
% \usepackage{amssymb}
% \usepackage{natbib}
% \usepackage{caption}
% \usepackage{placeins}
% \usepackage{float}
% \usepackage{setspace}
% \usepackage{cleveref}

\let\origtable\table
\let\endorigtable\endtable
\renewenvironment{table}[1][2] {
    \expandafter\origtable\expandafter[H]
} {
    \endorigtable
}

% \let\origfigure\figure
% \let\endorigfigure\endfigure
% \renewenvironment{figure}[1][2] {
%     \expandafter\origfigure\expandafter[H]
% } {
%     \endorigfigure
% }
\usepackage{float}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{caption}
\usepackage{setspace}
\usepackage{cleveref}

\begin{document}
\maketitle
\begin{abstract}
\noindent Gene-environment interactions can be efficiently estimated in
case-control data by methods that assume gene-environment independence
in the source population, but until recently such techniques required
parametric modelling of the genetic variables. The caseControlGE package
implements the methods of Stalder et. al. (2017, \emph{Biometrika},
\textbf{104}, 801-812) and Wang et. al. (2018, unpublished), which
exploit the assumption of gene-environment independence without placing
any assumptions on the marginal distributions of the genetic or
environmental variables. These methods are ideally suited for analyzing
complex polygenic data for which parametric distributional models are
not feasible. In addition to the two estimators, the package also
supplies a function to simulate case-control data and several helper
functions for use on model objects. Use of this package is illustrated
by simulating and analyzing data from a case-control study of breast
cancer.
\end{abstract}

{
\setcounter{tocdepth}{3}
\tableofcontents
}
\captionsetup{justification=centering, margin=0in}
\def\bbeta{\mbox{\boldmath $\beta$}} \def\pr{\hbox{pr}}
\def\E{{\mathbf E}}

\begin{titlepage}
\end{titlepage}

\onehalfspacing

\section{Introduction}

\subsection{caseControlGE package}

The \textbf{caseControlGE} package \citep{Asher2018R} contains tools for
the analysis of case-control data using \texttt{R} \citep{R2018}. It
implements the methods of \citet{Stalder2017} and
\citet{Wang2018unpublished}, both of which fall under the class of
semiparametric retrospective profile likelihood estimators. These
methods are the first available to exploit the assumption of
gene-environment independence while treating the genetic component
nonparametrically. As such, they are well suited to replace logistic
regression as the preferred method in situations where parametric
distributional models are not feasible, such as in the analysis of
complex polygenic data.

\textbf{caseControlGE} contains three main functions:
\texttt{simulateCC}, \texttt{spmle}, and \texttt{spmleCombo}, as well as
several helper functions. \Cref{sec:simulateCC} of this paper introduces
\texttt{simulateCC} in the context of simulating case-control data
analogous to the data analyzed in \cite{Wang2018unpublished}.
\Cref{sec:spmle} introduces \texttt{spmle} as a tool to analyze the
simulated data, and \cref{sec:spmleCombo} introduces \texttt{spmleCombo}
to conduct a more efficient analysis of the simulated data.

\subsection{Background}

Case-control studies are retrospective observational studies in which
the sample consists of a group of healthy subjects and a group of
diseased subjects. A crucial aspect of the case-control design is that
the outcome, disease status, is known \emph{before} sampling. The
ability to deliberately oversample diseased subjects makes the
case-control design cost effective, which is why it is widely popular in
studies of gene-environment interactions.

Given the genetic and environmental covariates \(G\) and \(E\), we
assume the risk of disease \(D\) in the underlying population follows
the model

\begin{equation}
  \pr(D=1 \mid G,X) = H\{\beta_0 + m(G,X,\bbeta)\}, \label{eq:logisticRisk}
\end{equation}

where \(H(x)=\{ 1 + \exp(-x)\}^{-1}\) is the logistic distribution
function and \(m(G,X,\bbeta)\) is a function that describes the joint
effect of \(G\) and \(X\) and is known up to the unspecified parameters
of interest \(\bbeta\).

Given the retrospective nature of case-control sampling, it is
surprising that standard prospective logistic regression can be used to
obtain unbiased estimates of \(\bbeta\) \citep{PrenticePyke1979}.
Logistic regression requires no assumptions about the joint distribution
of \(G\) and \(E\), but it suffers from low power when estimating
\(G * E\) interaction effects. To gain efficiency,
\citet{ChatterjeeCarroll2005} exploited the assumption of
gene-environment independence in the source population to maximize the
retrospective likelihood while profiling out the distribution of \(E\).
Their method is available as the function \texttt{snp.logistic} in the
\emph{Bioconductor} package \textbf{CGEN} \citep{CGEN2012}.

The method of \citeauthor{ChatterjeeCarroll2005}, and subsequent methods
utilizing the same retrospective profile likelihood framework, require a
parametric model for the distribution of \(G\) given \(E\). This becomes
difficult as the number and complexity of genetic variables in the model
grows. Capitalizing on advances in high-throughput genomics, genome-wide
association studies have identified scores of SNPs associated with
complex diseases such as cancers and diabetes. Modern case-control
studies of gene-environment interactions need efficient methodology that
allows for a flexible and arbitrarily complex genetic component, such as
multiple correlated SNPs and/or continuous polygenic risk scores.

The method of \citet{Stalder2017} extends the retrospective profile
likelihood framework of \citeauthor{ChatterjeeCarroll2005}, dispensing
with the need to model \(G\) parametrically. When the population disease
rate \(\pi_1\) is known, the retrospective profile loglikelihood can be
estimated (up to an additive constant) using just the case-control
sample and without modeling the distribution of \(G\). When \(\pi_1\) is
unknown but the disease is rare, estimates can be obtained using the
\emph{rare disease approximation} that \(\pi_1 \approx 0\), which
typically introduces negligible bias \citep{Stalder2017}.

\citet{Wang2018unpublished} proposed an improvement to the method of
\citet{Stalder2017} that increases the efficiency of the estimates with
no additional assumptions. This development relies on the observation
that the method of \citeauthor{Stalder2017} removes dependence on the
distribution of the genetic and environmental variables in two different
fashions; by treating the genetic and environmental variables
symmetrically \citeauthor{Wang2018unpublished} generate two sets of
parameter estimates that are combined to generate a more efficient
estimate.

\subsection{Implementation}

The semiparametric method of \citet{Stalder2017} is implemented as the
function \texttt{spmle} in \textbf{caseControlGE}, detailed in
\cref{sec:spmle}. Estimating the semiparametric profile likelihood is a
computationally intensive process, and significant effort was invested
in speeding up calculations. Estimation functions, including the
analytic gradient and hessian, are written in C++ and compiled using
\textbf{Rcpp} \citep{Eddelbuettel2013Rcpp}, providing a tremendous
speedup over native \texttt{R} code. Extensive benchmarking and code
profiling was conducted, and estimation functions were written to apply
matrix operations to contiguous blocks of memory whenever possible,
reducing memory latency and allowing modern processors to exploit data
level parallelism and perform the same operation on multiple data points
simultaneously.

The estimated semiparametric likelihood is maximized using the
quasi-Newton optimizer \textbf{ucminf} \citep{Nielsen2016ucminf} using
starting values from logistic regression. \texttt{ucminf} is
particularly well suited for this application because it allows us to
precondition the optimization with the analytic hessian, and it
evaluates the gradient after each call to the objective function.
Calculating the gradient along with the likelihood adds negligible
computational complexity, so we call a single C++ function to compute
them both, then return them separately to \texttt{ucminf}. This leads
\texttt{ucminf} to converge in roughly half the time of the next-fastest
optimizers (several of the various \texttt{R} implementations of the
BFGS algorithm tie for second place). The unmatched speed of
\texttt{ucminf} means we are willing to tolerate its bugs, which include
occasionally declaring convergence before actually converging. To
address this, \texttt{spmle} checks the gradient at the reported optimum
and restarts the optimization if necessary (with different starting
values).

Computational complexity of the asymptotic covariance estimation, which
contains a sum of the form
\(\sum_{i=1}^{n} \: \sum_{j=1}^{n} \: \sum_{k=1}^{n} \partial {\cal L}_{ijk}(\Omega) / \partial \Omega\),
was reduced from \(O(n^3)\) to \(O(n^2)\) by storing intermediate values
in a three-dimensional array. This increases speed at the cost of memory
usage, which climbs from \(O(n)\) to \(O(n^2)\), setting a practical
limit on sample size in the low tens of thousands for average personal
computers. This is sufficient to analyze all but the largest
case-control studies; covariance estimates for larger studies should be
computed using the bootstrap.

Asymptotic covariance estimates for the Symmetric Combination Estimator
of \citeauthor{Wang2018unpublished} converge slowly and unreliable in
practice, often providing poor coverage.
\citeauthor{Wang2018unpublished} recommend a balanced bootstrap, with
cases and controls resampled separately, to estimate covariance.
\textbf{caseControlGE} offers users with multicore computers the option
to speed up computation by using multiple processors. Parallelization is
implemented using the \texttt{R} base package \textbf{parallel}, which
is installed by default on all operating systems. Parallelization on
computers running Linux or macOS is done by forking the active
\texttt{R} session, saving time and memory. This option is unavailable
in Windows, so parallelization is fractionally slower because a PSOCK
cluster is created with a new instance of \texttt{R} running on each
core.

\section{Simulating case-control data with simulateCC} \label{sec:simulateCC}

\subsection{Data description}

\cite{Wang2018unpublished} demonstrate the utility of their method by
analyzing data from a case-control study of breast cancer. This
case-control sample is taken from a large prospective cohort at the
National Cancer Institute: the Prostate, Lung, Colorectal and Ovarian
(PLCO) cancer screening trial \citep{canzian2010comprehensive}. The
case-control study analyzed by \citeauthor{Wang2018unpublished} consists
of 658 cases and 753 controls sampled from a cohort of 64,440
non-Hispanic, white women aged 55 to 74, of whom 3.72\% developed breast
cancer \citep{pfeiffer2013risk}. The data are available from the
National Cancer Institute via a data transfer agreement, but cannot be
distributed with the \textbf{caseControlGE} package. Fortunately, we can
use the \textbf{caseControlGE} function \texttt{simulateCC} to generate
a similar data set for analysis.

Each of the 1411 subjects in the PLCO sample was genotyped for 21 SNPs
that have been previously associated with breast cancer based on large
genome-wide association studies. These SNPs were weighted by their
log-odds-ratio coefficients and summed to define a polygenic risk score
(PRS). A standardized version of this PRS, with mean zero and standard
deviation one, was used as the genetic risk factor \(G\) by
\citeauthor{Wang2018unpublished}. Early menarche is a known risk factor
for breast cancer, and \citeauthor{Wang2018unpublished} used a binary
indicator of whether the subject underwent early menarche as \(E\) (age
at menarche \textless{} 14). Several environmental variables were
recorded as part of the PLCO study, including body mass index (BMI).
There is some evidence that obese women have a reduced risk of breast
cancer, so in our simulation we will consider BMI in addition to the
variables modeled by \citeauthor{Wang2018unpublished}.

\subsection{Data simulation}

Genetic variables generated by \texttt{simulateCC} include SNPs and
three distributions of continuous PRS: Normal(0,1), Gamma(shape=20,
scale=20), and bimodal. Environmental variables can be binary or
Normal(0,1). To simulate case-control data with \texttt{simulateCC}, we
specify distributions for \(G\) and \(E\) and provide regression
coefficients \(\bbeta\) and intercept \(\beta_0\) from
\cref{eq:logisticRisk}. The function \texttt{simulateCC} generates
values of \(G\) and \(E\) for a simulated population, then simulates
binary \(D\) from its conditional distribution
\((D \mid G, X, \beta_0, \bbeta)\). A sample of \(n_1\) cases and
\(n_0\) controls is taken from this simulated population.

To determine the appropriate distributions to use when simulating \(G\)
and \(E\), we examine the PLCO data. In doing so, it is important to
keep in mind that the case control sample is not representative of the
source population. Case-control studies deliberately oversample cases,
so the distribution of \(G\) and \(E\) in the sample may be quite
different from the distribution of \(G\) and \(E\) in the population
(especially for variables that are strongly correlated with disease
status). To accurately simulate the genetic and environmental variables
from the PLCO study, we need to estimate their distributions
\emph{in the source population}.

\citeauthor{Wang2018unpublished} report \(\beta_G = 0.459\) with
\(p < 1e-4\), but they standardized \(G\) to mean zero and standard
deviation one \emph{in the case-control sample}. \(G\) has a strong
positive effect on disease risk, indicating that the distribution of
\((G|D=0)\) is meaningfully different from the distribution of
\((G|D=1)\). Specifically, \(\mathbf{E}(G|D=1) > \mathbf{E}(G|D=0)\).
With a population disease rate of 0.0372, this implies
\(\mathbf{E_{\rm pop}}(G) \approx \mathbf{E}(G|D=0) < 0\), where the
subscript pop emphasizes that the expectation is in the source
population.

This causes no problem for \citeauthor{Wang2018unpublished}, but it
presents us with the dilemma that \(G \nsim \hbox{N}(0,1)\). If we
simulate \(G \sim \hbox{N}(0,1)\) and use \(\beta_G = 0.459\) as
reported in \citeauthor{Wang2018unpublished}, our simulated
\((D \mid G, X, \beta_0, \bbeta)\) will not match the distribution of
the actual PLCO data.

If we did not have access to the PLCO data, our best option would be to
approximate \(\delta = \mathbf{E}(G|D=0)\), simulate
\(G \sim \hbox{N}(\delta, 1)\), and use \(\bbeta\) as reported in
\citeauthor{Wang2018unpublished}. While we cannot distribute the PLCO
data, we \emph{can} use it to estimate population parameters, so
approximating \(\delta\) is not necessary. The simplest and most common
way to estimate population parameters is to calculate them using just
the controls. Case-control designs are typically used to study
relatively rare diseases, and the bias introduced by using the cases as
a stand-in for the population is usually quite small.

When \(\pi_1\) is known, it is possible to calculate unbiased estimates
by weighting the cases and controls by \(\pi_1\) and \((1 - \pi_1)\),
respectively. (This technique is employed to great effect by
\citeauthor{Stalder2017}, and is the reason that \texttt{spmle} requires
the user to specify a value for \texttt{pi1}.)

We return to the PLCO data to conduct an analysis similar to that of
\citeauthor{Wang2018unpublished}, but with two environmental variables:
the indicator of early menarche and BMI. We will standardize the two
continuous variables due to their very different scales, but to make our
lives easier when we conduct subsequent simulations, we standardize them
to have mean zero and standard deviation one
\emph{in the source population}.

We calculate \(\mathbf{\widehat{E}_{\rm pop}}(\rm PRS)\),
\(\mathbf{\widehat{E}_{\rm pop}}(\text{early menarche})\), and
\(\mathbf{\widehat{E}_{\rm pop}}(\rm BMI)\) by weighting the means
within cases and controls by \(\pi_1\) and \((1 - \pi_1)\),
respectively. We calculate \(\widehat{\hbox{sd}}_{\rm pop}(\rm PRS)\)
and \(\widehat{\hbox{sd}}_{\rm pop}(\rm BMI)\) using the sample standard
deviations among the controls only. We have

\begin{align*}
  G = \frac{{\rm PRS} - \mathbf{\widehat{E}_{\rm pop}}(\rm PRS)}{\widehat{\hbox{sd}}_{\rm pop}(\rm PRS)}, && E_1 = \mathbf{I}(\texttt{age at menarche} < 14), && E_2 = \frac{{\rm BMI} - \mathbf{\widehat{E}_{\rm pop}}(\rm BMI)}{\widehat{\hbox{sd}}_{\rm pop}(\rm BMI)}.
\end{align*}

After this scaling, the distributions of \(G\) and \(E_2\) in the source
population can be well approximated by uncorrelated \(\hbox{N}(0, 1)\)
random variables. Binary environmental variable \(E_1\) is also
uncorrelated with \(G\), and has a frequency of 0.745 in the population.
We fit a model in these variables to the PLCO data using
\texttt{spmleCombo}, yielding the rest of the information we need to
simulate case control data:

\begin{align*}
  \pi_1   & =    0.0372        & n_0          & =    753               & n_1          & =     658          \\
  G       & \sim \hbox{N}(0,1) & E_1          & \sim \hbox{Bin}(0.745) & E_2          & \sim \hbox{N}(0,1) \\
  \beta_G & =    0.450         & \beta_{E_1}  & =    0.143             & \beta_{E_2}  & =    -0.019        \\
          &                    & \beta_{GE_1} & =   -0.195             & \beta_{GE_2} & =    -0.040
\end{align*}

The logistic intercept \(\beta_0\) is not consistently estimated by
logistic regression or either of the semiparametric methods in
\textbf{caseControlGE}, however it is typically of little interest. The
function \texttt{simulateCC} prints the population disease rate each
time it runs, so we run \texttt{simulateCC} several times with different
values of \(\beta_0\). Using a guess-and-check approach with increasing
sample size as we get closer, we manipulate \(\beta_0\) to match the
disease rate observed in the source population.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{#### Load the castControlGE package and set the random seed}
\KeywordTok{library}\NormalTok{(}\StringTok{"caseControlGE"}\NormalTok{)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{979}\NormalTok{)}

\NormalTok{#### Generate data with beta0 = -3 as a starting point}
\NormalTok{tmp =}\StringTok{ }\KeywordTok{simulateCC}\NormalTok{(}\DataTypeTok{ncase=}\DecValTok{1000}\NormalTok{, }\DataTypeTok{ncontrol=}\DecValTok{1000}\NormalTok{, }\DataTypeTok{beta0 =} \OperatorTok{-}\DecValTok{3}\NormalTok{, }\DataTypeTok{betaG_normPRS=}\FloatTok{0.450}\NormalTok{,}
                 \DataTypeTok{betaE_bin=}\FloatTok{0.143}\NormalTok{, }\DataTypeTok{betaE_norm=}\OperatorTok{-}\FloatTok{0.019}\NormalTok{, }\DataTypeTok{betaGE_normPRS_bin=}\OperatorTok{-}\FloatTok{0.195}\NormalTok{,}
                 \DataTypeTok{betaGE_normPRS_norm=}\OperatorTok{-}\FloatTok{0.040}\NormalTok{, }\DataTypeTok{E_bin_freq=}\FloatTok{0.745}\NormalTok{)}
\CommentTok{#> }
\CommentTok{#> Disease prevalance: 0.0520909090909091}
\NormalTok{#### Disease rate too high, try beta0 = -4}
\NormalTok{tmp =}\StringTok{ }\KeywordTok{simulateCC}\NormalTok{(}\DataTypeTok{ncase=}\DecValTok{1000}\NormalTok{, }\DataTypeTok{ncontrol=}\DecValTok{1000}\NormalTok{, }\DataTypeTok{beta0 =} \OperatorTok{-}\DecValTok{4}\NormalTok{, }\DataTypeTok{betaG_normPRS=}\FloatTok{0.450}\NormalTok{,}
                 \DataTypeTok{betaE_bin=}\FloatTok{0.143}\NormalTok{, }\DataTypeTok{betaE_norm=}\OperatorTok{-}\FloatTok{0.019}\NormalTok{, }\DataTypeTok{betaGE_normPRS_bin=}\OperatorTok{-}\FloatTok{0.195}\NormalTok{,}
                 \DataTypeTok{betaGE_normPRS_norm=}\OperatorTok{-}\FloatTok{0.040}\NormalTok{, }\DataTypeTok{E_bin_freq=}\FloatTok{0.745}\NormalTok{)}
\CommentTok{#> }
\CommentTok{#> Disease prevalance: 0.0212909427411371}
\NormalTok{#### Continue guessing, increasing sample size as we get closer (not run)}
\NormalTok{## tmp = simulateCC(ncase=1000, ncontrol=1000, beta0 = -3.5, ...}
\NormalTok{## tmp = simulateCC(ncase=10000, ncontrol=10000, beta0 = -3.4, ...}
\NormalTok{## tmp = simulateCC(ncase=100000, ncontrol=100000, beta0 = -3.4, ...}
\NormalTok{## tmp = simulateCC(ncase=100000, ncontrol=100000, beta0 = -3.41, ...}
\KeywordTok{rm}\NormalTok{(tmp)}
\end{Highlighting}
\end{Shaded}

After several iterations (commented out for speed), we determined that
\texttt{beta0 = -3.41} produces a population disease rate of 0.0372. Now
we generate our simulated PLCO data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{#### Set the random seed for reproducability}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{70}\NormalTok{)}

\NormalTok{#### Generate a synthetic data set that has similar properties to the PLCO data}
\NormalTok{dat =}\StringTok{ }\KeywordTok{simulateCC}\NormalTok{(}\DataTypeTok{ncase=}\DecValTok{658}\NormalTok{, }\DataTypeTok{ncontrol=}\DecValTok{753}\NormalTok{, }\DataTypeTok{beta0 =} \OperatorTok{-}\FloatTok{3.41}\NormalTok{, }\DataTypeTok{betaG_normPRS=}\FloatTok{0.450}\NormalTok{,}
                 \DataTypeTok{betaE_bin=}\FloatTok{0.143}\NormalTok{, }\DataTypeTok{betaE_norm=}\OperatorTok{-}\FloatTok{0.019}\NormalTok{, }\DataTypeTok{betaGE_normPRS_bin=}\OperatorTok{-}\FloatTok{0.195}\NormalTok{,}
                 \DataTypeTok{betaGE_normPRS_norm=}\OperatorTok{-}\FloatTok{0.040}\NormalTok{, }\DataTypeTok{E_bin_freq=}\FloatTok{0.745}\NormalTok{)}
\CommentTok{#> }
\CommentTok{#> Disease prevalance: 0.0362381630253141}
\end{Highlighting}
\end{Shaded}

\subsection{Confirming the G-E independence assumption}

The function \texttt{simulateCC} returns a list with elements
\texttt{D}, \texttt{G}, and \texttt{E}, which are numeric vectors or
matrices. We combine them into a \texttt{data.frame} to print the first
6 rows and tabulate by disease status.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{#### Check the simulated data and tabulate the number of cases & controls}
\KeywordTok{kable}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\KeywordTok{head}\NormalTok{(}\KeywordTok{as.data.frame}\NormalTok{(dat)), }\KeywordTok{table}\NormalTok{(dat}\OperatorTok{$}\NormalTok{D, }\DataTypeTok{dnn=}\StringTok{"D"}\NormalTok{)), }\DataTypeTok{cap=}\StringTok{"Simulated PLCO data"}\NormalTok{, }\DataTypeTok{book=}\NormalTok{T)}
\end{Highlighting}
\end{Shaded}

\begin{table}
\caption{Simulated PLCO data}

\centering
\begin{tabular}[t]{rrrr}
\toprule
D & G & E.1 & E.2\\
\midrule
0 & 0.1336533 & 1 & 0.3866567\\
0 & 0.4328288 & 0 & 1.4536655\\
0 & 0.3389738 & 1 & -1.0088425\\
0 & -1.4542346 & 1 & 0.7076604\\
0 & -1.0777144 & 1 & -0.2864078\\
0 & 1.4280646 & 1 & 1.6047819\\
\bottomrule
\end{tabular}
\centering
\begin{tabular}[t]{lr}
\toprule
D & Freq\\
\midrule
0 & 753\\
1 & 658\\
\bottomrule
\end{tabular}
\end{table}

Case-control data generated by \texttt{simulateCC} is sorted by disease
status (which is why the first 6 rows do not have a single case), but
the sample size is correct. Before we calculate the \texttt{spmle}, we
will check the assumption of gene-environment independence in the source
population. In our case, this check is largely perfunctory because we
did not provide the arguments \texttt{regress\_E\_bin\_on\_G\_normPRS}
or \texttt{regress\_E\_norm\_on\_G\_normPRS} to \texttt{simulateCC}, so
the genetic and environmental variates were drawn from independent
distributions.

But when analyzing real data, it is crucial to verify this assumption.
Violations of the \(G\)-\(E\) independence assumption can introduce bias
in the estimates of interaction parameters between the specific genetic
and environmental variables in violation of \(G\)-\(E\) independence
(the other parameters in the model appear unaffected in simulation
studies by \citeauthor{Stalder2017}).

We do this by checking for dependence between \texttt{G} and \texttt{E}
in the controls. Environmental variable \(E_1\) is binary, so we use a
two sample \emph{t}-test of \(G\) over the two levels of \(E_1\). To
test for dependence between \(G\) and \(E_2\), we conduct a correlation
test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{#### Save the indices of all controls in dat}
\NormalTok{controls =}\StringTok{ }\KeywordTok{which}\NormalTok{(dat}\OperatorTok{$}\NormalTok{D }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{)}

\NormalTok{#### t-test of G over the levels of E1}
\KeywordTok{pander}\NormalTok{(}\KeywordTok{t.test}\NormalTok{(dat}\OperatorTok{$}\NormalTok{G[controls] }\OperatorTok{~}\StringTok{ }\NormalTok{dat}\OperatorTok{$}\NormalTok{E[controls, }\DecValTok{1}\NormalTok{]), }\DataTypeTok{split.cells=}\DecValTok{11}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}cccccc@{}}
\caption{Welch Two Sample t-test: \texttt{dat\$G{[}controls{]}} by
\texttt{dat\$E{[}controls,\ 1{]}}}\tabularnewline
\toprule
\begin{minipage}[b]{0.14\columnwidth}\centering\strut
Test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\centering\strut
df\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering\strut
P value\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\centering\strut
Alternative hypothesis\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering\strut
mean in group 0\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering\strut
mean in group 1\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.14\columnwidth}\centering\strut
Test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\centering\strut
df\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering\strut
P value\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\centering\strut
Alternative hypothesis\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering\strut
mean in group 0\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering\strut
mean in group 1\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.14\columnwidth}\centering\strut
-0.7291\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\centering\strut
317\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering\strut
0.4665\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\centering\strut
two.sided\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering\strut
-0.1163\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering\strut
-0.05508\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{#### correlation test between G and E2}
\KeywordTok{pander}\NormalTok{(}\KeywordTok{cor.test}\NormalTok{(dat}\OperatorTok{$}\NormalTok{G[controls], dat}\OperatorTok{$}\NormalTok{E[controls, }\DecValTok{2}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}ccccc@{}}
\caption{Pearson's product-moment correlation:
\texttt{dat\$G{[}controls{]}} and
\texttt{dat\$E{[}controls,\ 2{]}}}\tabularnewline
\toprule
\begin{minipage}[b]{0.20\columnwidth}\centering\strut
Test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\centering\strut
df\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering\strut
P value\strut
\end{minipage} & \begin{minipage}[b]{0.30\columnwidth}\centering\strut
Alternative hypothesis\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering\strut
cor\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.20\columnwidth}\centering\strut
Test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\centering\strut
df\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering\strut
P value\strut
\end{minipage} & \begin{minipage}[b]{0.30\columnwidth}\centering\strut
Alternative hypothesis\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\centering\strut
cor\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.20\columnwidth}\centering\strut
-0.8129\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\centering\strut
751\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering\strut
0.4165\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\centering\strut
two.sided\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\centering\strut
-0.02965\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Now that we are satisfied that the assumption of gene-environment
independence has not been violated, we can exploit this assumption using
the two semiparametric retrospective methods of \textbf{caseControlGE}.

\section{Analyzing case-control data with spmle} \label{sec:spmle}

\subsection{Known and rare disease} \label{sec:spmle.knownRare}

The function \texttt{spmle} is the backbone of \textbf{caseControlGE};
it is called on its own to evaluate the SPMLE of
\citeauthor{Stalder2017}, and it is the key component of the Symmetric
Combination Estimator of \citeauthor{Wang2018unpublished}. Calling
\texttt{spmle} is slightly different from calling other estimation
commands like \texttt{lm} or \texttt{glm} because we do not specify the
model formula to \texttt{spmle}. Instead we specify which variables are
genetic and which are environmental, and \texttt{spmle} fits the
formula: \texttt{D {\raise.17ex\hbox{$\scriptstyle\sim$}} G * E}.

We fit the gene-environment interaction model with \texttt{spmle}, and
compare it to the estimates from standard logistic regression. We do not
need to fit the logistic regression model with a call to \texttt{glm}
because \texttt{spmle} fits a logistic regression model to obtain
starting values. This logistic regression model is returned with the
fitted \texttt{spmle} object.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{#### Fit the spmle to the simulated PLCO data}
\NormalTok{spmleFit1 =}\StringTok{ }\KeywordTok{spmle}\NormalTok{(}\DataTypeTok{D=}\NormalTok{D, }\DataTypeTok{G=}\NormalTok{G, }\DataTypeTok{E=}\NormalTok{E, }\DataTypeTok{pi1=}\FloatTok{0.0372}\NormalTok{, }\DataTypeTok{data=}\NormalTok{dat)}

\NormalTok{#### Print coefficient estimates from spmle and the logistic model returned by spmle}
\KeywordTok{kable}\NormalTok{(}\KeywordTok{summary}\NormalTok{(spmleFit1)}\OperatorTok{$}\NormalTok{coefficients, }\DataTypeTok{caption=}\StringTok{"spmle, known pi1"}\NormalTok{, }\DataTypeTok{digits=}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrr@{}}
\caption{spmle, known pi1}\tabularnewline
\toprule
& Estimate & Std. Error & z value &
Pr(\textgreater{}\textbar{}z\textbar{})\tabularnewline
\midrule
\endfirsthead
\toprule
& Estimate & Std. Error & z value &
Pr(\textgreater{}\textbar{}z\textbar{})\tabularnewline
\midrule
\endhead
(Intercept) & -0.3226 & 0.1049 & -3.0755 & 0.0021\tabularnewline
G & 0.5808 & 0.1033 & 5.6203 & 0.0000\tabularnewline
E1 & 0.1762 & 0.1332 & 1.3225 & 0.1860\tabularnewline
E2 & 0.0430 & 0.0565 & 0.7604 & 0.4470\tabularnewline
G:E1 & -0.2426 & 0.1064 & -2.2807 & 0.0226\tabularnewline
G:E2 & -0.0436 & 0.0432 & -1.0091 & 0.3129\tabularnewline
\bottomrule
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{kable}\NormalTok{(}\KeywordTok{summary}\NormalTok{(spmleFit1}\OperatorTok{$}\NormalTok{glm_fit)}\OperatorTok{$}\NormalTok{coefficients, }\DataTypeTok{caption=}\StringTok{"logistic regression"}\NormalTok{, }\DataTypeTok{digits=}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrr@{}}
\caption{logistic regression}\tabularnewline
\toprule
& Estimate & Std. Error & z value &
Pr(\textgreater{}\textbar{}z\textbar{})\tabularnewline
\midrule
\endfirsthead
\toprule
& Estimate & Std. Error & z value &
Pr(\textgreater{}\textbar{}z\textbar{})\tabularnewline
\midrule
\endhead
(Intercept) & -0.3014 & 0.1152 & -2.6160 & 0.0089\tabularnewline
G & 0.5513 & 0.1111 & 4.9610 & 0.0000\tabularnewline
E1 & 0.1549 & 0.1311 & 1.1814 & 0.2375\tabularnewline
E2 & 0.0435 & 0.0562 & 0.7730 & 0.4395\tabularnewline
G:E1 & -0.2263 & 0.1279 & -1.7695 & 0.0768\tabularnewline
G:E2 & -0.0130 & 0.0574 & -0.2258 & 0.8213\tabularnewline
\bottomrule
\end{longtable}

The parameter estimates are extremely similar between the two models,
but the \texttt{spmle} has smaller standard errors for the interaction
terms. Logistic regression uncovers some evidence of a \texttt{G:E1}
interaction between the PRS and early menarche, but the result is not
significant at the 0.05 level. The \texttt{spmle} is able to provide
stronger evidence of a \texttt{G:E1} interaction because the estimated
standard error of the \texttt{G:E1} coefficient is 20\% larger with
logistic regression than the \texttt{spmle}, giving a variance increase
of almost 45\%.

In this instance we know the true population disease rate
\(\pi_1=0.0372\). If \(\pi_1\) were unknown we would calculate the
\texttt{spmle} under the assumption that \(\pi_1 \approx 0\).
Calculating the rare disease approximation using \texttt{spmle} is as
simple as specifying \texttt{pi1 = 0} in the function call.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{kable}\NormalTok{(}\KeywordTok{summary}\NormalTok{(}\KeywordTok{spmle}\NormalTok{(}\DataTypeTok{D=}\NormalTok{D, }\DataTypeTok{G=}\NormalTok{G, }\DataTypeTok{E=}\NormalTok{E, }\DataTypeTok{pi1=}\DecValTok{0}\NormalTok{, }\DataTypeTok{data=}\NormalTok{dat))}\OperatorTok{$}\NormalTok{coef, }\DataTypeTok{cap=}\StringTok{"spmle, rare disease"}\NormalTok{, }\DataTypeTok{dig=}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrr@{}}
\caption{spmle, rare disease}\tabularnewline
\toprule
& Estimate & Std. Error & z value &
Pr(\textgreater{}\textbar{}z\textbar{})\tabularnewline
\midrule
\endfirsthead
\toprule
& Estimate & Std. Error & z value &
Pr(\textgreater{}\textbar{}z\textbar{})\tabularnewline
\midrule
\endhead
(Intercept) & -0.3253 & 0.1054 & -3.0857 & 0.0020\tabularnewline
G & 0.5862 & 0.1054 & 5.5617 & 0.0000\tabularnewline
E1 & 0.1791 & 0.1336 & 1.3404 & 0.1801\tabularnewline
E2 & 0.0428 & 0.0566 & 0.7562 & 0.4495\tabularnewline
G:E1 & -0.2436 & 0.1051 & -2.3175 & 0.0205\tabularnewline
G:E2 & -0.0437 & 0.0416 & -1.0492 & 0.2941\tabularnewline
\bottomrule
\end{longtable}

The estimates and standard errors are nearly identical to the model with
known \(\pi_1\), indicating that a valid estimator can be obtained even
when the disease rate is unknown.

\subsection{Reduced model test} \label{sec:spmle.reduced}

Body mass index does not appear to be a significant predictor in this
model. The coefficients for the \(E_2\) main effect and the \(G*E_2\)
interaction are near zero and both terms have large \(p\) values, so we
fit a reduced model without BMI. To demonstrate the options controlling
optimization, we disable hessian preconditioning and supply bad starting
values to the optimizer.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{#### Fit the reduced spmle with bad starting values}
\NormalTok{spmleRed =}\StringTok{ }\KeywordTok{spmle}\NormalTok{(}\DataTypeTok{D=}\NormalTok{D, }\DataTypeTok{G=}\NormalTok{G, }\DataTypeTok{E=}\NormalTok{E[,}\DecValTok{1}\NormalTok{], }\DataTypeTok{pi1=}\FloatTok{0.0372}\NormalTok{, }\DataTypeTok{data=}\NormalTok{dat, }
                 \DataTypeTok{startvals=}\KeywordTok{rep}\NormalTok{(}\OtherTok{NA}\NormalTok{, }\DecValTok{4}\NormalTok{), }\DataTypeTok{control=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{use_hess=}\OtherTok{FALSE}\NormalTok{))}
\CommentTok{#> ucminf retry 1 of 2}
\end{Highlighting}
\end{Shaded}

With starting values of \texttt{NA}, \texttt{ucminf} is unable to
converge during its first attempt. \texttt{splme} checks whether
\texttt{ucminf} has converged and, seeing that it has not, prints
``\texttt{ucminf retry 1 of 2}'' and restarts the optimization with
different starting values. The number of retries, convergence criterion,
and other optimization parameters can be passed as elements of the
\texttt{control} argument.

\texttt{summary.spmle} reports the number of retries, number of
\texttt{ucminf} iterations, and maximum gradient at the optimum, so we
can confirm that the model really did converge while we check the
parameter estimates.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{#### Check convergence and parameter estimates}
\KeywordTok{summary}\NormalTok{(spmleRed)}
\CommentTok{#> }
\CommentTok{#> Call:}
\CommentTok{#> spmle(D = D, G = G, E = E[, 1], pi1 = 0.0372, data = dat, control = list(use_hess = FALSE), }
\CommentTok{#>     startvals = rep(NA, 4))}
\CommentTok{#> }
\CommentTok{#> Pearson Residuals: }
\CommentTok{#>     Min       1Q   Median       3Q      Max  }
\CommentTok{#> -1.9511  -0.9175  -0.6480   1.0055   2.1736  }
\CommentTok{#> }
\CommentTok{#> Coefficients:}
\CommentTok{#>             Estimate Std. Error z value Pr(>|z|)    }
\CommentTok{#> (Intercept)  -0.3221     0.1048  -3.075  0.00211 ** }
\CommentTok{#> G             0.5808     0.1034   5.616 1.96e-08 ***}
\CommentTok{#> E[, 1]        0.1737     0.1331   1.305  0.19187    }
\CommentTok{#> G:E[, 1]     -0.2400     0.1064  -2.256  0.02408 *  }
\CommentTok{#> ---}
\CommentTok{#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1}
\CommentTok{#> }
\CommentTok{#>     Null deviance: 1949.7  on 1410  degrees of freedom}
\CommentTok{#> Residual deviance: 1848.1  on 1407  degrees of freedom}
\CommentTok{#> AIC: 1856.1 }
\CommentTok{#> UCMINF retries: 1, iterations: 14, max gradient at convergence: 4.917e-08}
\end{Highlighting}
\end{Shaded}

We see that not only did the model converge, but it converged to nearly
the same parameter estimates as the full model. We conduct a likelihood
ratio test using \texttt{anova}.

The function \texttt{spmle} returns an \texttt{S3} object of class
\texttt{"spmle"}. \textbf{caseControlGE} contains \texttt{spmle} methods
for all applicable \texttt{S3} generics, such as \texttt{summary.spmle},
\texttt{print.spmle}, \texttt{confint.spmle}, etc. If the function
\texttt{anova} is called on \texttt{spmle} objects, the method
\texttt{anova.spmle} is used to calculate likelihood ratio tests of the
models. This is a valid way to test full vs reduced \texttt{spmle}
models because the loglikelihood reported by \texttt{logLik.spmle} is
accurate up to an additive constant. However, \texttt{anova} should not
be used to compare an \texttt{spmle} object to a model fit by a
different method.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{#### Likelihood ratio test for reduced vs full model}
\KeywordTok{anova}\NormalTok{(spmleRed, spmleFit1)}
\CommentTok{#> Likelihood ratio test}
\CommentTok{#> }
\CommentTok{#> Model 1: D ~ G * E[, 1]}
\CommentTok{#> Model 2: D ~ G * E}
\CommentTok{#>   #Df  LogLik Df Chisq Pr(>Chisq)}
\CommentTok{#> 1   4 -924.03                    }
\CommentTok{#> 2   6 -923.34  2 1.387     0.4998}
\KeywordTok{kable}\NormalTok{(}\KeywordTok{anova}\NormalTok{(spmleRed, spmleFit1))}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rrrrr@{}}
\toprule
\#Df & LogLik & Df & Chisq & Pr(\textgreater{}Chisq)\tabularnewline
\midrule
\endhead
4 & -924.0328 & NA & NA & NA\tabularnewline
6 & -923.3394 & 2 & 1.386955 & 0.4998349\tabularnewline
\bottomrule
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pander}\OperatorTok{::}\KeywordTok{pander}\NormalTok{(}\KeywordTok{anova}\NormalTok{(spmleRed, spmleFit1))}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}ccccc@{}}
\caption{Likelihood ratio test}\tabularnewline
\toprule
\begin{minipage}[b]{0.07\columnwidth}\centering\strut
\#Df\strut
\end{minipage} & \begin{minipage}[b]{0.11\columnwidth}\centering\strut
LogLik\strut
\end{minipage} & \begin{minipage}[b]{0.06\columnwidth}\centering\strut
Df\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\centering\strut
Chisq\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\centering\strut
Pr(\textgreater{}Chisq)\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.07\columnwidth}\centering\strut
\#Df\strut
\end{minipage} & \begin{minipage}[b]{0.11\columnwidth}\centering\strut
LogLik\strut
\end{minipage} & \begin{minipage}[b]{0.06\columnwidth}\centering\strut
Df\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\centering\strut
Chisq\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\centering\strut
Pr(\textgreater{}Chisq)\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.07\columnwidth}\centering\strut
4\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\centering\strut
-924\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\centering\strut
NA\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\centering\strut
NA\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\centering\strut
NA\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.07\columnwidth}\centering\strut
6\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\centering\strut
-923.3\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\centering\strut
2\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\centering\strut
1.387\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\centering\strut
0.4998\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\section{Analyzing case-control data with spmleCombo} \label{sec:spmleCombo}

In the code below we coerce \texttt{dat} into a \texttt{data.frame} and
drop \(E_2\) from the \texttt{data} that is passed to \texttt{spmle}. \%
spmleRed = spmle(D=D, G=G, E=E.1, pi1=0.0372,
data=as.data.frame(dat){[},-4{]})

\bibliographystyle{biomAbhra}\bibliography{alexrefs}


\end{document}
